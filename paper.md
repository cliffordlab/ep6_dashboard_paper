---
title: 'An open-source system for monitoring activity in a built environment combining edge and fog computing'
tags:
  - Python
  - In-door monitoring
  - Fog Computing
  - Audio Analysis
  - Vision Analysis

authors:
  - name: Arjunsinh Nakum
    orcid: 0000-0000-0000-0000
    equal-contrib: true
    affiliation: "1, 2" # (Multiple affiliations must be quoted)

  - name: Krishna MVS
    equal-contrib: true # (This is how you can denote equal contributions between multiple authors)
    affiliation: 2
  
  - name: Ratan Singh
    equal-contrib: true # (This is how you can denote equal contributions between multiple authors)
    affiliation: 2
  
  - name: Nicolas Shu
    equal-contrib: true # (This is how you can denote equal contributions between multiple authors)
    affiliation: 2
  
  - name: Chaitra Hegde
    equal-contrib: true # (This is how you can denote equal contributions between multiple authors)
    affiliation: 2
  
  - name: Pradyumna B. Suresha
    equal-contrib: true # (This is how you can denote equal contributions between multiple authors)
    affiliation: 2
  
  - name: Dr. Hyeokhyen Kwon
    equal-contrib: true # (This is how you can denote equal contributions between multiple authors)
    affiliation: 2
  
  - name: Dr. Yash Kiarashi
    equal-contrib: true # (This is how you can denote equal contributions between multiple authors)
    affiliation: 2
  
  - name: Dr. Gari D. Clifford
    equal-contrib: true # (This is how you can denote equal contributions between multiple authors)
    affiliation: 2


affiliations:
 - name: Department of Electrical and Computer Engineering, Georgia Institute of Technology, USA
   index: 1
 - name: Department of Biomedical Informatics, Emory University, USA
   index: 2
 - name: Department of Biomedical Engineering, Georgia Institute of Technology, USA
   index: 3

date: 13 August 2017
bibliography: paper.bib

# Optional fields if submitting to a AAS journal too, see this blog post:
# https://blog.joss.theoj.org/2018/12/a-new-collaboration-with-aas-publishing
aas-doi: 10.3847/xxxxx <- update this with the DOI from AAS once you know it.
aas-journal: Astrophysical Journal <- The name of the AAS journal.
---

# Summary

At Executive Park 6, we developed a low-cost indoor monitoring system preserving the privacy using Raspberry Pi 4, Respeaker USB microphone array, Raspberry Pi Camera and Google Coral USB TPU for people sufferingfrom cognitive impairment diseases like Dementia, Alzheimer's disease etc. with their privacy presevered. With custom real-time algorithms, we detect the position of participants and try to assess their engagement with each other through poses. To collate all the data and effective monitoring, we developed `EP6 Dashboard` which helps combining all the data from Audio, Camera and Bluetooth pipelines together and presents the analysis of this data using Computer Vision, Signal Processing and Machine Learning Techniques. `EP6 Dashboard` is one stop solution for monitoring the sensor network, analyzing and visualizing the multimodal data collected.

# Statement of need

As detection techniques have improved over the years, Alzheimer's and other different forms of dementia have come to receive an increasing amount of attention. In addition to being the sixth most common cause of mortality in the US, Alzheimer's disease is also thought to be the possible cause of dementia in more than 6 million people. While the average person experiences a natural reduction in cognitive function with aging, some people experience a far more rapid decline, which frequently progresses to Alzheimer's disease or another form of dementia. These people are classified as having mild cognitive impairment, making them the study's population.


`EP6 Dashboard` is an unified portal developed using python packages and React framework to monitor the indoor activities through audio, visual and spatial tracking. It monitors following activities:
1. Audio
2. Visual
3. Indoor Temperature and Humidity
4. Bluetooth


# System Architecture 

To implement the aforementioned system, we have followed a scalable three tier architecture using Flask as application server hosted with nginx as load balancer and reverse proxy. Frontend is designed with React for and served through nginx as webserver. We are using influxdb as database for storing the time series data generated by the edge devices. Redis is used as key-value store to interact with background python processes, whose output is consumed on the dashboard. MySQL database is used for storing the authentication and authorization of users.

![Architecture Diagram of EP6 Dashboard](assets/Architecture_Diagram.png)



# Monitoring the Sensor Network

For a distributed sensor network application like this, it becomes very important to ensure that all of the sensors are working faithfully and recording the data. To ensure this, we developed a robust mechanism to check the health of each of the Raspberry Pi and sensors mounted to it. The results from this upstream system is sourced to the dashboard. 

Section A) in fig. II represents position of each Raspberry Pi on EP6 schematic with region monitored by them. If clicked on a particular region, it shows the status of sensors connected to that Raspberry Pi as shown in section C) of fig. II. Lastly, table shown in section B) of fig. II represents the list of all Raspberry Pi in EP6 with their status and an option to reboot them remotely.  

![Sensor Network Monitoring (A) Schematic of EP6 defining the positions of Raspberry Pi with region monitored by them (B) Status of each Raspberry Pi with option to reboot them remotely (C) Status of Sensors connected to Raspberry Pi in Region 9 ](assets/EP6_Dashboard_Status_highlighted.png)


# Audio Pipeline Analysis

As part of audio pipeline, we collect the audio features of the participants through respeaker USB microphone arrays placed on ceiling. We don't store the audio itself but its computed feature to preserve participant privacy. Through these features, we perform speaker diarization followed by tagging the respective participants groups. Through these, we are measuring the degree of engagement in each group. 

![Audio Pipeline (A) EP6 Schematic with position of microphone arrays (B) Slider to analyze the activity between two specified hours (C) Heatmap depicting the activity level in EP6](assets/EP6_Dashboard_Audio.png)

Occupancy analysis plays an important role in identification of how physical location of the EP6 correlates with the interaction among the participants. fig. III represents the image of Audio section on EP6 dashboard. Section A) shows the physical location of microphone arrays in the EP6 lab. To have an hour dependent view of occupancy, we also plot the heatmap of occupancy based on the audio signals as shown in section C) which can be controlled through slider shown in section B) of fig. III. One can vary the hours and see the occupancy change with respect to hours. 

![Audio Channels for a particular microphone array](assets/Audio_graph.png)

# Visual Pipeline Analysis

Through the means of vision pipeline, we are trying to record and analyze the features in movement, action, and interaction of participants/patients through computer vision techniques, which are later displayed in the vision segment of the dashboard. With movement, we are trying to analyze the path taken on the EP6 floor in a certain time frame over multiple iteration for every individual human subject. With action, we try to analyze posture of every single individual (sitting, standing, leaning to talk). With interactions, we aim to register f-formations for further research purposes that occurs during participants interactions. All the above-mentioned processing is done through the collection of Image feed from all the individual raspberry Pi’s at every second. However, it is unsaid truth that Pi’s don’t always gather data at every instance of time due to processing fluctuations. With the said state of image collection, an algorithm manages to stitch images from all the cameras, of the given instance in time, into one singular image that shows the overview of the EP6 floor and activity going on.

Dashboard displays the processed data in 4 different ways, Heatmap, Occupancy Map, and Camera Location. Heatmap, as the name suggests, displays the occupancy in terms of heat signature to visualize the population distribution throughout the EP6 floor. On contrary, Occupancy Map gives more specific location of all the individuals, at any given time, in the EP6. Lastly, Camera Location provides the location of the places from where the image originates.

![Location of individuals (red dots) within floor plan layout of EP6](assets/EP6_occupancy.jpg)


# Bluetooth Pipeline Analysis

In the Bluetooth pipeline analysis, we gather the BLE signals from the BLE Beacons carried by the participants through the Raspberry Pi's placed in the ceiling. We only store the MAC address and the corresponding RSSI of the BLE Beacons thus preserving participant privacy. With this, we perform RNSI weighted RSSI based Tri-lateration. Through these, we are tracking the movement and thereby activities of the participants during their interactions in EP6.

![Audio Pipeline (A) EP6 Schematic with position of microphone arrays (B) Slider to analyze the activity between two specified hours (C) Heatmap depicting the activity level in EP6](assets/EP6_Dashboard_Audio.png)

Occupancy analysis of different areas in EP6 helps us correspond the movements of participants and their activites in   fig. IV represents the image of Bluetooth Localisation section on EP6 dashboard. Section A) shows the location of Raspberry Pi's in the EP6 lab. Section B) shows the real-time location of participants in EP6


# Acknowledgements
This work is part of the Cognitive Empowerment Program, which is supported by a generous investment from the James M. Cox Foundation and Cox Enterprises, Inc., in support of Emory’s Brain Health Center and Georgia Institute of Technology.

# References

@article{Pearson:2017,
  	url = {http://adsabs.harvard.edu/abs/2017arXiv170304627P},
  	Archiveprefix = {arXiv},
  	Author = {{Pearson}, S. and {Price-Whelan}, A.~M. and {Johnston}, K.~V.},
  	Eprint = {1703.04627},
  	Journal = {ArXiv e-prints},
  	Keywords = {Astrophysics - Astrophysics of Galaxies},
  	Month = mar,
  	Title = {{Gaps in Globular Cluster Streams: Pal 5 and the Galactic Bar}},
  	Year = 2017
}

@book{Binney:2008,
  	url = {http://adsabs.harvard.edu/abs/2008gady.book.....B},
  	Author = {{Binney}, J. and {Tremaine}, S.},
  	Booktitle = {Galactic Dynamics: Second Edition, by James Binney and Scott Tremaine.~ISBN 978-0-691-13026-2 (HB).~Published by Princeton University Press, Princeton, NJ USA, 2008.},
  	Publisher = {Princeton University Press},
  	Title = {{Galactic Dynamics: Second Edition}},
  	Year = 2008
}

@article{gaia,
    author = {{Gaia Collaboration}},
    title = "{The Gaia mission}",
    journal = {Astronomy and Astrophysics},
    archivePrefix = "arXiv",
    eprint = {1609.04153},
    primaryClass = "astro-ph.IM",
    keywords = {space vehicles: instruments, Galaxy: structure, astrometry, parallaxes, proper motions, telescopes},
    year = 2016,
    month = nov,
    volume = 595,
    doi = {10.1051/0004-6361/201629272},
    url = {http://adsabs.harvard.edu/abs/2016A%26A...595A...1G},
}

@article{astropy,
    author = {{Astropy Collaboration}},
    title = "{Astropy: A community Python package for astronomy}",
    journal = {Astronomy and Astrophysics},
    archivePrefix = "arXiv",
    eprint = {1307.6212},
    primaryClass = "astro-ph.IM",
    keywords = {methods: data analysis, methods: miscellaneous, virtual observatory tools},
    year = 2013,
    month = oct,
    volume = 558,
    doi = {10.1051/0004-6361/201322068},
    url = {http://adsabs.harvard.edu/abs/2013A%26A...558A..33A}
}

@misc{fidgit,
  author = {A. M. Smith and K. Thaney and M. Hahnel},
  title = {Fidgit: An ungodly union of GitHub and Figshare},
  year = {2020},
  publisher = {GitHub},
  journal = {GitHub repository},
  url = {https://github.com/arfon/fidgit}
}
